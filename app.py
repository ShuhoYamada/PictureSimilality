from typing import Optional
import io

import streamlit as st
import numpy as np

from src.preprocessor import load_and_binarize, load_and_binarize_with_original, extract_contour, resample_contour
from src.visualizer import plot_contour


st.set_page_config(page_title="2æ¬¡å…ƒå½¢çŠ¶é¡ä¼¼åº¦è§£æ", layout="wide")
st.title("2æ¬¡å…ƒå½¢çŠ¶é¡ä¼¼åº¦è§£æ")

st.sidebar.header("å…¥åŠ›è¨­å®š")
# Allow multiple files for global view, but keep ability to inspect single image
uploaded_files = st.sidebar.file_uploader(
    "ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ (TIFF/PNG/JPG) â€” Global/Local ä¸¡å¯¾å¿œ",
    accept_multiple_files=True,
    type=["tif", "tiff", "png", "jpg", "jpeg"],
)
threshold = st.sidebar.slider("é–¾å€¤ (0=Otsu)", 0, 255, 0)
epsilon_factor = st.sidebar.slider("approx epsilon factor", 0.001, 0.05, 0.01)
num_points = st.sidebar.slider("ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ç‚¹æ•°", 50, 1000, 200)
include_holes = st.sidebar.checkbox("ç©´ï¼ˆå†…å´è¼ªéƒ­ï¼‰ã‚’å«ã‚ã‚‹", value=True)
min_hole_area = st.sidebar.slider("ç©´ã®æœ€å°é¢ç© (pxÂ²)", 10, 1000, 100) if include_holes else 100
num_fourier = st.sidebar.slider("ãƒ•ãƒ¼ãƒªã‚¨ä¿‚æ•°æ•° (num_coeffs)", 4, 128, 16)
method = st.sidebar.selectbox("åŸ‹ã‚è¾¼ã¿æ‰‹æ³•", ["MDS", "TSNE"])

# ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°è¨­å®š
st.sidebar.header("ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°è¨­å®š")
enable_clustering = st.sidebar.checkbox("ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã‚’æœ‰åŠ¹ã«ã™ã‚‹", value=False)
if enable_clustering:
    cluster_method = st.sidebar.selectbox(
        "ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°æ‰‹æ³•",
        ["K-means", "DBSCAN", "éšå±¤çš„ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°"],
        help="K-means: æŒ‡å®šã—ãŸæ•°ã®ã‚¯ãƒ©ã‚¹ã‚¿ã«åˆ†å‰²\nDBSCAN: å¯†åº¦ãƒ™ãƒ¼ã‚¹ï¼ˆè‡ªå‹•ã§ã‚¯ãƒ©ã‚¹ã‚¿æ•°æ±ºå®šï¼‰\néšå±¤çš„: éšå±¤çš„ã«çµ±åˆ"
    )
    if cluster_method == "K-means":
        n_clusters = st.sidebar.slider("ã‚¯ãƒ©ã‚¹ã‚¿æ•°", 2, 10, 3)
        cluster_params = {"method": "kmeans", "n_clusters": n_clusters}
    elif cluster_method == "DBSCAN":
        eps = st.sidebar.slider("è¿‘å‚åŠå¾„ (eps)", 0.1, 2.0, 0.5, 0.1)
        min_samples = st.sidebar.slider("æœ€å°ã‚µãƒ³ãƒ—ãƒ«æ•°", 1, 10, 2)
        cluster_params = {"method": "dbscan", "eps": eps, "min_samples": min_samples}
    else:  # éšå±¤çš„ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°
        n_clusters = st.sidebar.slider("ã‚¯ãƒ©ã‚¹ã‚¿æ•°", 2, 10, 3)
        cluster_params = {"method": "hierarchical", "n_clusters": n_clusters}
else:
    cluster_params = None


@st.cache_data
def _process_image(file_bytes: bytes, threshold: int, epsilon_factor: float, num_points: int, include_holes: bool = True, min_hole_area: int = 100):
    """ç”»åƒã‚’å‡¦ç†ã—ã¦è¼ªéƒ­ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
    
    Returns:
        include_holes=True ã®å ´åˆ: ((outer, holes, islands), binary)
        include_holes=False ã®å ´åˆ: (outer, binary)
    """
    binary = load_and_binarize(file_bytes, threshold if threshold > 0 else None)
    contour_data = extract_contour(binary, epsilon_factor, include_holes=include_holes, min_hole_area=min_hole_area)
    if contour_data is None:
        return None, binary
    
    if include_holes and isinstance(contour_data, tuple):
        # ã‚¿ãƒ—ãƒ«ã®å ´åˆ: (outer, holes, islands)
        outer, holes, islands = contour_data
        outer_resampled = resample_contour(outer, num_points)
        # ç©´ã¨å³¶ã‚‚ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼ˆç‚¹æ•°ã¯æ¯”ä¾‹é…åˆ†ï¼‰
        holes_resampled = []
        for hole in holes:
            hole_pts = max(20, int(num_points * len(hole) / max(len(outer), 1)))
            holes_resampled.append(resample_contour(hole, hole_pts))
        islands_resampled = []
        for island in islands:
            island_pts = max(20, int(num_points * len(island) / max(len(outer), 1)))
            islands_resampled.append(resample_contour(island, island_pts))
        return (outer_resampled, holes_resampled, islands_resampled), binary
    else:
        # å˜ç´”ãªé…åˆ—ã®å ´åˆ
        resampled = resample_contour(contour_data, num_points)
        return resampled, binary


@st.cache_data
def _process_image_with_original(file_bytes: bytes, threshold: int, epsilon_factor: float, num_points: int, include_holes: bool = True, min_hole_area: int = 100):
    """å…ƒç”»åƒã‚‚ä¸€ç·’ã«è¿”ã™å‡¦ç†é–¢æ•°"""
    original, binary = load_and_binarize_with_original(file_bytes, threshold if threshold > 0 else None)
    contour_data = extract_contour(binary, epsilon_factor, include_holes=include_holes, min_hole_area=min_hole_area)
    if contour_data is None:
        return None, original, binary
    
    if include_holes and isinstance(contour_data, tuple):
        outer, holes, islands = contour_data
        outer_resampled = resample_contour(outer, num_points)
        holes_resampled = [resample_contour(h, max(20, int(num_points * len(h) / max(len(outer), 1)))) for h in holes]
        islands_resampled = [resample_contour(isl, max(20, int(num_points * len(isl) / max(len(outer), 1)))) for isl in islands]
        return (outer_resampled, holes_resampled, islands_resampled), original, binary
    else:
        resampled = resample_contour(contour_data, num_points)
        return resampled, original, binary


@st.cache_data
def _process_multiple(files_data: tuple, threshold: int, epsilon: float, num_points: int, num_fourier: int, method: str, include_holes: bool = True, min_hole_area: int = 100):
    """è¤‡æ•°ç”»åƒã‚’å‡¦ç†ã™ã‚‹ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«ãƒ‡ãƒ¼ã‚¿ã¯ãƒã‚¤ãƒˆåˆ—ã®ã‚¿ãƒ—ãƒ«ã¨ã—ã¦æ¸¡ã™ï¼‰"""
    from src.global_features import compute_global_embedding

    contours = {}
    skipped = []
    for name, data in files_data:
        try:
            contour, _ = _process_image(data, threshold if threshold > 0 else None, epsilon, num_points, include_holes, min_hole_area)
            if contour is None:
                skipped.append(name)
            else:
                contours[name] = contour
        except Exception:
            skipped.append(name)

    if len(contours) < 2:
        return None, skipped

    df, skipped_more = compute_global_embedding(contours, num_fourier=num_fourier, method=method)
    skipped += skipped_more
    return df, skipped


# ç”»åƒãƒ‡ãƒ¼ã‚¿ã‚’ä¿æŒã™ã‚‹ãŸã‚ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥é–¢æ•°
@st.cache_data
def _get_contours_and_images(files_data: tuple, threshold: int, epsilon: float, num_points: int, include_holes: bool, min_hole_area: int):
    """è¼ªéƒ­ã¨å…ƒç”»åƒãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
    
    Returns:
        contours: {name: contour_data} - contour_dataã¯(outer, holes, islands)ã‚¿ãƒ—ãƒ«ã¾ãŸã¯np.ndarray
        images: {name: original_image}
        skipped: list of skipped file names
    """
    contours = {}
    images = {}  # å…ƒç”»åƒã‚’ä¿æŒ
    skipped = []
    
    for name, data in files_data:
        try:
            original, binary = load_and_binarize_with_original(data, threshold if threshold > 0 else None)
            contour_data = extract_contour(binary, epsilon, include_holes=include_holes, min_hole_area=min_hole_area)
            if contour_data is None:
                skipped.append(name)
            else:
                # è¼ªéƒ­ãƒ‡ãƒ¼ã‚¿ã‚’ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
                if include_holes and isinstance(contour_data, tuple):
                    outer, holes, islands = contour_data
                    outer_resampled = resample_contour(outer, num_points)
                    holes_resampled = [resample_contour(h, max(20, int(num_points * len(h) / max(len(outer), 1)))) for h in holes]
                    islands_resampled = [resample_contour(isl, max(20, int(num_points * len(isl) / max(len(outer), 1)))) for isl in islands]
                    contours[name] = (outer_resampled, holes_resampled, islands_resampled)
                else:
                    contours[name] = resample_contour(contour_data, num_points)
                images[name] = original  # å…ƒç”»åƒã‚’ä¿å­˜
        except Exception:
            skipped.append(name)
    
    return contours, images, skipped


tabs = st.tabs(["Global Map", "Single Image", "Local Comparison", "é¡ä¼¼ç”»åƒæ¤œç´¢"])

# --- Global Map Tab
with tabs[0]:
    st.header("Global Map")
    if not uploaded_files or len(uploaded_files) < 2:
        st.info("è¤‡æ•°ã®ç”»åƒã‚’ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ï¼ˆ2æšä»¥ä¸Šï¼‰ã€‚")
    else:
        # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’äº‹å‰ã«èª­ã¿è¾¼ã‚“ã§ã‚¿ãƒ—ãƒ«ã«å¤‰æ›ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥å¯¾å¿œï¼‰
        files_data = []
        for f in uploaded_files:
            f.seek(0)  # ãƒ•ã‚¡ã‚¤ãƒ«ãƒã‚¤ãƒ³ã‚¿ã‚’ãƒªã‚»ãƒƒãƒˆ
            files_data.append((f.name, f.read()))
        files_data_tuple = tuple(files_data)
        
        df_skipped = _process_multiple(files_data_tuple, threshold, epsilon_factor, num_points, num_fourier, method, include_holes, min_hole_area)
        # _process_multiple returns either (df, skipped) or (None, skipped) or None
        if df_skipped is None or df_skipped[0] is None:
            skipped = [] if df_skipped is None else df_skipped[1]
            st.error("æœ‰åŠ¹ãªè¼ªéƒ­ã‚’æŒã¤ç”»åƒãŒ2æšä»¥ä¸Šè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’èª¿æ•´ã—ã¦ãã ã•ã„ã€‚")
            if skipped:
                st.warning(f"ä»¥ä¸‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯è¼ªéƒ­æŠ½å‡ºã«å¤±æ•—ã—ã¾ã—ãŸ: {skipped}")
        else:
            df, skipped = df_skipped
            
            # ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã‚’é©ç”¨
            if enable_clustering and cluster_params is not None:
                from src.global_features import cluster_shapes, compute_cluster_stats
                df = cluster_shapes(df, **cluster_params)
                cluster_stats = compute_cluster_stats(df)
            
            # å‡¦ç†æˆåŠŸæ•°ã‚’è¡¨ç¤º
            st.success(f"âœ… {len(df)}æšã®ç”»åƒã‚’è§£æã—ã¾ã—ãŸ")
            
            from src.visualizer import plot_global_map

            fig = plot_global_map(df, show_clusters=enable_clustering)
            st.plotly_chart(fig, use_container_width=True)
            
            # ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°çµæœã‚’è¡¨ç¤º
            if enable_clustering and "cluster" in df.columns:
                st.subheader("ğŸ“Š ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°çµæœ")
                
                # ã‚¯ãƒ©ã‚¹ã‚¿ã”ã¨ã®ã‚µãƒãƒªãƒ¼
                n_clusters = df["cluster"].nunique()
                noise_count = len(df[df["cluster"] == -1]) if -1 in df["cluster"].values else 0
                
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("ã‚¯ãƒ©ã‚¹ã‚¿æ•°", n_clusters - (1 if noise_count > 0 else 0))
                with col2:
                    st.metric("åˆ†é¡æ¸ˆã¿", len(df) - noise_count)
                with col3:
                    if noise_count > 0:
                        st.metric("ãƒã‚¤ã‚ºï¼ˆæœªåˆ†é¡ï¼‰", noise_count)
                
                # ã‚¯ãƒ©ã‚¹ã‚¿ã”ã¨ã®ãƒ¡ãƒ³ãƒãƒ¼ä¸€è¦§
                with st.expander("ğŸ—‚ï¸ ã‚¯ãƒ©ã‚¹ã‚¿åˆ¥ãƒ¡ãƒ³ãƒãƒ¼ä¸€è¦§"):
                    for cluster_id in sorted(df["cluster"].unique()):
                        if cluster_id == -1:
                            st.write("**ãƒã‚¤ã‚ºï¼ˆæœªåˆ†é¡ï¼‰:**")
                        else:
                            st.write(f"**Cluster {cluster_id}:**")
                        members = df[df["cluster"] == cluster_id]["label"].tolist()
                        st.write(", ".join(members))
                        st.markdown("---")
            
            # åŸ‹ã‚è¾¼ã¿åº§æ¨™ãƒ‡ãƒ¼ã‚¿ã‚’è¡¨ç¤ºï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            with st.expander("ğŸ“Š åŸ‹ã‚è¾¼ã¿åº§æ¨™ãƒ‡ãƒ¼ã‚¿ã‚’è¡¨ç¤º"):
                st.dataframe(df)

            if skipped:
                st.warning(f"ä»¥ä¸‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯è¼ªéƒ­æŠ½å‡ºã«å¤±æ•—ã—ã¾ã—ãŸ: {skipped}")

# --- Single Image Tab
with tabs[1]:
    st.header("Single Image Inspection")
    st.write("å·¦ã®ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰å˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦è¼ªéƒ­ã‚’ç¢ºèªã§ãã¾ã™ã€‚")
    single = st.file_uploader("å˜ä¸€ç”»åƒ (Single inspection)", accept_multiple_files=False, type=["tif", "tiff", "png", "jpg", "jpeg"], key="single")
    if single is None:
        st.info("ã“ã“ã§ã¯1æšã®ç”»åƒã‚’é¸ã‚“ã§è¼ªéƒ­ã‚’ç¢ºèªã§ãã¾ã™ã€‚")
    else:
        try:
            file_bytes = single.read()
            contour, original, binary = _process_image_with_original(file_bytes, threshold if threshold > 0 else None, epsilon_factor, num_points, include_holes, min_hole_area)
            
            # å…ƒç”»åƒã¨å‡¦ç†å¾Œç”»åƒã‚’ä¸¦ã¹ã¦è¡¨ç¤º
            st.subheader("ç”»åƒæ¯”è¼ƒ")
            img_col1, img_col2 = st.columns(2)
            with img_col1:
                st.image(original, caption="å…ƒç”»åƒ (Original)", use_container_width=True)
            with img_col2:
                st.image(binary, caption="äºŒå€¤åŒ–ç”»åƒ (Binarized)", use_container_width=True)
            
            st.markdown("---")
            
            if contour is None:
                st.error("è¼ªéƒ­ãŒæ¤œå‡ºã§ãã¾ã›ã‚“ã§ã—ãŸã€‚é–¾å€¤è¨­å®šã‚„ç”»åƒã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            else:
                st.subheader("æŠ½å‡ºã•ã‚ŒãŸè¼ªéƒ­")
                fig = plot_contour(contour, title=single.name)
                st.plotly_chart(fig, use_container_width=True)
        except Exception as e:
            st.exception(e)

# --- Local Comparison Tab
with tabs[2]:
    st.header("Local Comparison")
    st.write("2æšã®ç”»åƒã‚’é¸æŠã—ã¦ã€ä½ç½®åˆã‚ã›ï¼ˆé‡å¿ƒ + Procrustes / ICPï¼‰ã¨å·®åˆ†ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚")

    col1, col2 = st.columns(2)
    with col1:
        ref = st.file_uploader("åŸºæº–ç”»åƒ (reference)", accept_multiple_files=False, type=["tif", "tiff", "png", "jpg", "jpeg"], key="ref")
    with col2:
        tgt = st.file_uploader("æ¯”è¼ƒç”»åƒ (target)", accept_multiple_files=False, type=["tif", "tiff", "png", "jpg", "jpeg"], key="tgt")

    icp_checkbox = st.checkbox("ICP ã«ã‚ˆã‚‹å¾®èª¿æ•´ã‚’è¡Œã†", value=True)
    run = st.button("è§£æé–‹å§‹ (Align & Compute)")

    if run:
        if ref is None or tgt is None:
            st.error("åŸºæº–ç”»åƒã¨æ¯”è¼ƒç”»åƒã®ä¸¡æ–¹ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
        else:
            try:
                b1 = ref.read()
                b2 = tgt.read()
                ref_contour, ref_orig, ref_bin = _process_image_with_original(b1, threshold if threshold > 0 else None, epsilon_factor, num_points, include_holes, min_hole_area)
                tgt_contour, tgt_orig, tgt_bin = _process_image_with_original(b2, threshold if threshold > 0 else None, epsilon_factor, num_points, include_holes, min_hole_area)

                # å…ƒç”»åƒã¨å‡¦ç†å¾Œç”»åƒã‚’ä¸¦ã¹ã¦è¡¨ç¤º
                st.subheader("å…¥åŠ›ç”»åƒã®æ¯”è¼ƒ")
                
                # åŸºæº–ç”»åƒ: å…ƒç”»åƒã¨äºŒå€¤åŒ–ç”»åƒ
                st.write(f"**åŸºæº–ç”»åƒ: {ref.name}**")
                ref_col1, ref_col2 = st.columns(2)
                with ref_col1:
                    st.image(ref_orig, caption="å…ƒç”»åƒ (Original)", use_container_width=True)
                with ref_col2:
                    st.image(ref_bin, caption="äºŒå€¤åŒ–ç”»åƒ (Binarized)", use_container_width=True)
                
                # æ¯”è¼ƒç”»åƒ: å…ƒç”»åƒã¨äºŒå€¤åŒ–ç”»åƒ
                st.write(f"**æ¯”è¼ƒç”»åƒ: {tgt.name}**")
                tgt_col1, tgt_col2 = st.columns(2)
                with tgt_col1:
                    st.image(tgt_orig, caption="å…ƒç”»åƒ (Original)", use_container_width=True)
                with tgt_col2:
                    st.image(tgt_bin, caption="äºŒå€¤åŒ–ç”»åƒ (Binarized)", use_container_width=True)
                
                st.markdown("---")

                if ref_contour is None or tgt_contour is None:
                    st.error("ã„ãšã‚Œã‹ã®ç”»åƒã§è¼ªéƒ­ãŒæ¤œå‡ºã§ãã¾ã›ã‚“ã§ã—ãŸã€‚é–¾å€¤ã‚„ç”»åƒã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
                else:
                    from src.local_analysis import align_shapes, compute_local_distance
                    from src.visualizer import plot_local_comparison

                    aligned_tgt, transform = align_shapes(tgt_contour, ref_contour, use_icp=icp_checkbox)

                    # Compute distances: source=ref, target=aligned_tgt
                    _, hausdorff, chamfer, target_to_source = compute_local_distance(ref_contour, aligned_tgt)

                    st.subheader("è¼ªéƒ­ã®ä½ç½®åˆã‚ã›çµæœ")
                    fig = plot_local_comparison(ref_contour, aligned_tgt, target_to_source, title=f"{ref.name} â†” {tgt.name}")
                    st.plotly_chart(fig, use_container_width=True)

                    st.markdown("---")
                    metric_col1, metric_col2 = st.columns(2)
                    with metric_col1:
                        st.metric("Hausdorff distance (px)", f"{hausdorff:.3f}")
                    with metric_col2:
                        st.metric("Chamfer mean (px)", f"{chamfer:.3f}")

                    with st.expander("è©³ç´°: å¤‰æ›è¡Œåˆ—ãƒ»å¤‰æ›é‡"):
                        st.write(transform)

            except Exception as e:
                st.exception(e)

# --- Similar Image Search Tab
with tabs[3]:
    st.header("é¡ä¼¼ç”»åƒæ¤œç´¢")
    st.write("ç”»åƒã‚’é¸æŠã™ã‚‹ã¨ã€ä¼¼ã¦ã„ã‚‹ç”»åƒã‚’é¡ä¼¼åº¦é †ã«è¡¨ç¤ºã—ã¾ã™ã€‚")
    
    if not uploaded_files or len(uploaded_files) < 2:
        st.info("è¤‡æ•°ã®ç”»åƒã‚’ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ï¼ˆ2æšä»¥ä¸Šï¼‰ã€‚")
    else:
        # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™
        files_data = []
        for f in uploaded_files:
            f.seek(0)
            files_data.append((f.name, f.read()))
        files_data_tuple = tuple(files_data)
        
        # è¼ªéƒ­ã¨ç”»åƒã‚’å–å¾—
        with st.spinner("ç”»åƒã‚’å‡¦ç†ä¸­..."):
            contours, images, skipped = _get_contours_and_images(
                files_data_tuple, threshold, epsilon_factor, num_points, include_holes, min_hole_area
            )
        
        if len(contours) < 2:
            st.error("æœ‰åŠ¹ãªè¼ªéƒ­ã‚’æŒã¤ç”»åƒãŒ2æšä»¥ä¸Šè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        else:
            # ç‰¹å¾´é‡ã‚’äº‹å‰è¨ˆç®—ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼‰
            @st.cache_data
            def _compute_features_cached(contours_keys: tuple, _contours: dict, _num_fourier: int):
                """ç‰¹å¾´é‡ã‚’è¨ˆç®—ã—ã¦ã‚­ãƒ£ãƒƒã‚·ãƒ¥"""
                from src.global_features import compute_all_features
                return compute_all_features(_contours, _num_fourier, use_holes=True)
            
            # ç‰¹å¾´é‡ã‚’è¨ˆç®—
            contours_keys = tuple(sorted(contours.keys()))
            with st.spinner(f"ç‰¹å¾´é‡ã‚’è¨ˆç®—ä¸­... ({len(contours)}æš)"):
                precomputed_features = _compute_features_cached(contours_keys, contours, num_fourier)
            
            # æ¤œç´¢å¯¾è±¡ã®ç”»åƒã‚’é¸æŠ
            available_images = list(contours.keys())
            
            col1, col2 = st.columns([1, 2])
            
            with col1:
                st.subheader("ğŸ” æ¤œç´¢å¯¾è±¡ã‚’é¸æŠ")
                query_image = st.selectbox(
                    "åŸºæº–ç”»åƒ",
                    available_images,
                    key="query_select"
                )
                
                top_k = st.slider("è¡¨ç¤ºã™ã‚‹é¡ä¼¼ç”»åƒæ•°", 1, min(10, len(available_images) - 1), 5)
                
                # é¸æŠã—ãŸç”»åƒã‚’è¡¨ç¤º
                if query_image and query_image in images:
                    st.image(images[query_image], caption=f"é¸æŠä¸­: {query_image}", use_container_width=True)
            
            with col2:
                if query_image:
                    from src.global_features import find_similar_shapes
                    
                    # é¡ä¼¼ç”»åƒã‚’æ¤œç´¢ï¼ˆäº‹å‰è¨ˆç®—æ¸ˆã¿ç‰¹å¾´é‡ã‚’ä½¿ç”¨ï¼‰
                    similar = find_similar_shapes(
                        query_image, contours, num_fourier, top_k,
                        precomputed_features=precomputed_features
                    )
                    
                    if similar:
                        st.subheader(f"ğŸ“Š é¡ä¼¼ç”»åƒ TOP {len(similar)}")
                        
                        # ã‚°ãƒªãƒƒãƒ‰è¡¨ç¤º
                        cols_per_row = 3
                        for i in range(0, len(similar), cols_per_row):
                            cols = st.columns(cols_per_row)
                            for j, col in enumerate(cols):
                                idx = i + j
                                if idx < len(similar):
                                    name, score = similar[idx]
                                    with col:
                                        if name in images:
                                            st.image(images[name], use_container_width=True)
                                        st.markdown(f"**{idx + 1}. {name}**")
                                        st.progress(score, text=f"é¡ä¼¼åº¦: {score:.1%}")
                    else:
                        st.warning("é¡ä¼¼ç”»åƒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
            
            # é¡ä¼¼åº¦ãƒãƒˆãƒªãƒƒã‚¯ã‚¹ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            st.markdown("---")
            st.subheader("ğŸ“ˆ é¡ä¼¼åº¦ãƒãƒˆãƒªãƒƒã‚¯ã‚¹")
            
            num_images = len(contours)
            st.info(f"ğŸ“Š å¯¾è±¡ç”»åƒæ•°: {num_images}æš")
            
            if num_images > 500:
                st.warning(f"âš ï¸ ç”»åƒæ•°ãŒå¤šã„ãŸã‚ï¼ˆ{num_images}æšï¼‰ã€ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—è¡¨ç¤ºã¯æœ€å¤§100æšã®ã‚µãƒ³ãƒ—ãƒ«ã«åˆ¶é™ã•ã‚Œã¾ã™ã€‚å®Œå…¨ãªãƒãƒˆãƒªãƒƒã‚¯ã‚¹ã¯CSVã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã§ãã¾ã™ã€‚")
            
            col_matrix1, col_matrix2 = st.columns(2)
            
            with col_matrix1:
                show_heatmap = st.checkbox("ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã‚’è¡¨ç¤º", value=num_images <= 100)
            
            with col_matrix2:
                max_heatmap_samples = st.slider(
                    "ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—æœ€å¤§ã‚µãƒ³ãƒ—ãƒ«æ•°",
                    min_value=20,
                    max_value=200,
                    value=100,
                    help="ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã«è¡¨ç¤ºã™ã‚‹æœ€å¤§ç”»åƒæ•°ã€‚ãƒ¡ãƒ¢ãƒªã¨ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã®ãŸã‚åˆ¶é™ã—ã¦ã„ã¾ã™ã€‚"
                )
            
            from src.global_features import compute_pairwise_similarity, export_full_similarity_matrix
            
            # ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—è¡¨ç¤º
            if show_heatmap:
                with st.spinner(f"é¡ä¼¼åº¦ã‚’è¨ˆç®—ä¸­... ({min(num_images, max_heatmap_samples)}æš)"):
                    progress_bar = st.progress(0)
                    
                    def update_progress(p):
                        progress_bar.progress(min(p, 1.0))
                    
                    sim_matrix, was_sampled = compute_pairwise_similarity(
                        contours, num_fourier, 
                        max_samples=max_heatmap_samples,
                        progress_callback=update_progress
                    )
                    progress_bar.empty()
                
                if not sim_matrix.empty:
                    if was_sampled:
                        st.info(f"ğŸ² è¡¨ç¤ºç”¨ã«{max_heatmap_samples}æšã‚’ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ã¾ã—ãŸã€‚")
                    
                    import plotly.express as px
                    
                    fig = px.imshow(
                        sim_matrix.values,
                        x=sim_matrix.columns,
                        y=sim_matrix.index,
                        color_continuous_scale="RdYlGn",
                        aspect="auto",
                        title="é¡ä¼¼åº¦ãƒãƒˆãƒªãƒƒã‚¯ã‚¹ï¼ˆç·‘=é¡ä¼¼ã€èµ¤=éé¡ä¼¼ï¼‰"
                    )
                    fig.update_layout(
                        xaxis_title="",
                        yaxis_title="",
                        xaxis=dict(tickangle=45),
                        height=max(400, min(800, len(sim_matrix) * 5))
                    )
                    st.plotly_chart(fig, use_container_width=True)
            
            # CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆå®Œå…¨ç‰ˆï¼‰
            st.markdown("### ğŸ“¥ å®Œå…¨ãªé¡ä¼¼åº¦ãƒãƒˆãƒªãƒƒã‚¯ã‚¹ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")
            
            if st.button("é¡ä¼¼åº¦ãƒãƒˆãƒªãƒƒã‚¯ã‚¹ã‚’ç”Ÿæˆï¼ˆCSVï¼‰", key="generate_full_matrix"):
                with st.spinner(f"å…¨{num_images}æšã®é¡ä¼¼åº¦ã‚’è¨ˆç®—ä¸­...ï¼ˆå¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã®å ´åˆã€æ•°åˆ†ã‹ã‹ã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ï¼‰"):
                    csv_bytes = export_full_similarity_matrix(contours, num_fourier)
                
                if csv_bytes:
                    st.download_button(
                        "ğŸ“¥ CSVã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                        csv_bytes,
                        "similarity_matrix_full.csv",
                        "text/csv",
                        key="download_full_matrix"
                    )
                    st.success(f"âœ… {num_images}x{num_images}ã®é¡ä¼¼åº¦ãƒãƒˆãƒªãƒƒã‚¯ã‚¹ã‚’ç”Ÿæˆã—ã¾ã—ãŸã€‚")
            
            if skipped:
                st.warning(f"ä»¥ä¸‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯è¼ªéƒ­æŠ½å‡ºã«å¤±æ•—ã—ã¾ã—ãŸ: {skipped}")